<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
    <title>Longevity in software engineering</title>
    <link rel="stylesheet" type="text/css" href="/assets/style.css">
    
    </head>
    <body>
    <header>
        <h1 class="breadcrumbs"><a href="/">~jelford</a> / <a href="/blog.html">blog:</a></h1>
    </header>
    <article itemscope itemtype="http://schema.org/BlogPosting">
        <header>
        <h2 itemprop="name">Longevity in software engineering</h2>
        <p class="post-meta-info">
            Published on 
            <time itemprop="datePublished" datetime="2020-06-14">2020-06-14</time>. 
            <a href="posts/2020-06-14-lindy-effect-in-software.html">(permalink)</a>
        </p>
        </header>
        <main itemprop="articleBody">
        <p>How long should we expect themes and technologies in software engineering to last?
In this post, we'll look at how long individual projects &quot;last&quot; based on data from GitHub
and try to draw conclusions around what that means for choosing foundational software.</p>
<p>Software comes and goes - except when it doesn't; we can all think of technologies like
Fortran and COBOL that have been around forever, and continue to fulfil a useful purpose
in their particular niche. When we're building something new, 
what kind of technologies should we build on? Should we seek maturity
and stability - perhaps seeking to reduce the constant churn of keeping up with
the latest updates, and benefit from the battle-hardening effect of exposure to
the real world and the passing of time; or should we eschew staleness, and 
build on foundations that aren't already aproaching the end of their shelf-life - 
benefiting from the latest advances in technology, and learning from the mistakes
of those who went before. When we look at our depenedencies on other projects, can
we guess how long they will continue to be around for?</p>
<p>It goes without saying that our choice will depend on what it is we're building;
are we most concerned with getting an idea in front of users ASAP, or with
the ongoing cost of maintenance once we've shipped? Are we reasonably sure about
the problem space, or do we expect a lot of iteration before we have the basics
right? </p>
<h2>what can we know?</h2>
<p>One way to start thinking about answering these questions would be to talk about
the longevity of tools and projects. Can we make predictions about how long a
given technology will be around, given its history? That's what we'll look at
in the rest of this post: can we judge whether a project will still be around
in a few years' time based on how long it has been around.</p>
<h2>prior art</h2>
<ul>
<li>
<p>There was a pretty popular blog post a few years ago called <a href="https://mcfunley.com/choose-boring-technology">choose boring technology</a>. 
In it, McKinley talks about the idea of <em>innovation tokens</em> - the idea is that you
only have so much <em>innovation</em> to spend, and if you go off the beaten path, then
you're using those up - by implication, you don't have so many left to spend on
your &quot;real&quot; problem (the thing that gave you a reason to write software in the
first place).</p>
</li>
<li>
<p>Taleb and the Antifragile Software folks talk about the 
<a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy Effect</a>. The idea here is
that we can just a thing's life expentancy by how long it has already been
around - and that the life expentancy <em>increases</em> with every year something
has been around (contingent on the thing not having some natural upper limit;
sofware being an obvious example of something non-perishable).</p>
</li>
</ul>
<p>Inspired by both of these ideas, let's make a hypothesis:</p>
<blockquote>
<p>The longer a project has been around, the longer its expected remaining life.</p>
</blockquote>
<p>Notice, this prediction is obviously false for things with naturally bounded
lifespans, since remaining life expectancy must decrease as you approach that
upper bound. But what about software projects?</p>
<h2>what can we measure?</h2>
<p>GitHub provide a <a href="https://console.cloud.google.com/marketplace/details/github/github-repos?filter=solution-type:dataset&amp;q=github&amp;id=46ee22ab-2ca4-4750-81a7-3ee0f0150dcb">BigQuery dataset</a>
comprising 3TB of data on activity around GitHub-hosted open source projects.</p>
<p>This dataset gives us a few things, but most usefully (I hope): commit history.
Let's simplify things and say that a project's age is the time between the first
and last commit, and that it's said to be &quot;done&quot; if there has been no commit in
the last 3 months (i.e. exclude still-active projects from the sample).</p>
<p>Here's the query I used to pull information about the first and last commits for
each project:</p>
<pre style="background-color:#2b303b;">
<span style="background-color:#2b303b;color:#b48ead;">with</span><span style="background-color:#2b303b;color:#c0c5ce;"> commits_by_repo </span><span style="background-color:#2b303b;color:#b48ead;">as</span><span style="background-color:#2b303b;color:#c0c5ce;"> (
  </span><span style="background-color:#2b303b;color:#b48ead;">SELECT</span><span style="background-color:#2b303b;color:#c0c5ce;"> rname </span><span style="background-color:#2b303b;color:#b48ead;">as</span><span style="background-color:#2b303b;color:#c0c5ce;"> repo_name, </span><span style="background-color:#2b303b;color:#d08770;">cs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">committer</span><span style="background-color:#2b303b;color:#c0c5ce;">.time_sec ts, </span><span style="background-color:#2b303b;color:#b48ead;">commit
  FROM </span><span style="background-color:#2b303b;color:#c0c5ce;">`</span><span style="background-color:#2b303b;color:#a3be8c;">bigquery-public-data.github_repos.commits</span><span style="background-color:#2b303b;color:#c0c5ce;">` cs
  </span><span style="background-color:#2b303b;color:#b48ead;">CROSS JOIN</span><span style="background-color:#2b303b;color:#c0c5ce;"> unnest(</span><span style="background-color:#2b303b;color:#d08770;">cs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">repo_name</span><span style="background-color:#2b303b;color:#c0c5ce;">) </span><span style="background-color:#2b303b;color:#b48ead;">as</span><span style="background-color:#2b303b;color:#c0c5ce;"> rname
  </span><span style="background-color:#2b303b;color:#b48ead;">join </span><span style="background-color:#2b303b;color:#c0c5ce;">`</span><span style="background-color:#2b303b;color:#a3be8c;">bigquery-public-data.github_repos.sample_repos</span><span style="background-color:#2b303b;color:#c0c5ce;">` sam_rs 
    </span><span style="background-color:#2b303b;color:#b48ead;">on</span><span style="background-color:#2b303b;color:#c0c5ce;"> rname = </span><span style="background-color:#2b303b;color:#d08770;">sam_rs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">repo_name
  </span><span style="background-color:#2b303b;color:#b48ead;">where </span><span style="background-color:#2b303b;color:#d08770;">sam_rs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">watch_count </span><span style="background-color:#2b303b;color:#c0c5ce;">&gt; </span><span style="background-color:#2b303b;color:#d08770;">3
  </span><span style="background-color:#2b303b;color:#b48ead;">and </span><span style="background-color:#2b303b;color:#d08770;">committer</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">time_sec </span><span style="background-color:#2b303b;color:#c0c5ce;">&gt;= </span><span style="background-color:#2b303b;color:#d08770;">2674800</span><span style="background-color:#2b303b;color:#c0c5ce;">
)
</span><span style="background-color:#2b303b;color:#b48ead;">select 
  </span><span style="background-color:#2b303b;color:#d08770;">cs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">repo_name </span><span style="background-color:#2b303b;color:#b48ead;">as</span><span style="background-color:#2b303b;color:#c0c5ce;"> project_name, 
  </span><span style="background-color:#2b303b;color:#96b5b4;">min</span><span style="background-color:#2b303b;color:#c0c5ce;">(</span><span style="background-color:#2b303b;color:#d08770;">cs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">ts</span><span style="background-color:#2b303b;color:#c0c5ce;">) earliest_commit_sec, 
  </span><span style="background-color:#2b303b;color:#96b5b4;">max</span><span style="background-color:#2b303b;color:#c0c5ce;">(</span><span style="background-color:#2b303b;color:#d08770;">cs</span><span style="background-color:#2b303b;color:#c0c5ce;">.</span><span style="background-color:#2b303b;color:#d08770;">ts</span><span style="background-color:#2b303b;color:#c0c5ce;">) latest_commit_sec, 
  </span><span style="background-color:#2b303b;color:#96b5b4;">count</span><span style="background-color:#2b303b;color:#c0c5ce;">(distinct </span><span style="background-color:#2b303b;color:#b48ead;">commit</span><span style="background-color:#2b303b;color:#c0c5ce;">) number_of_commits
</span><span style="background-color:#2b303b;color:#b48ead;">from</span><span style="background-color:#2b303b;color:#c0c5ce;"> commits_by_repo cs
</span><span style="background-color:#2b303b;color:#b48ead;">group by</span><span style="background-color:#2b303b;color:#c0c5ce;"> project_name
</span><span style="background-color:#2b303b;color:#b48ead;">order by</span><span style="background-color:#2b303b;color:#c0c5ce;"> earliest_commit_sec </span><span style="background-color:#2b303b;color:#b48ead;">asc

</span></pre>
<p>And <a href="lindy-tech/ProjectCommitTimingAnalysis.ipynb">here's</a> the notebook
I used to analyze the results and produce the plots below. If you want to
follow along you'll have to pull the data out of BigQuery and point the
notebook at your own CSV file.</p>
<p>A few remarks:</p>
<ul>
<li>
<p>The data quality here is... patchy. A few examples:</p>
<ul>
<li>a <a href="https://github.com/volumio/Volumio2.git">JavaScript project</a> with commits
before the invention of HTML</li>
<li>More than one version of golang with <a href="https://github.com/cloudflare/go/commits/0bb0b61d6a85b2a1a33dcbc418089656f2754d32">commits</a> that look like they might be
imported from the very inception of C</li>
<li>This project with <a href="https://github.com/openmole/openmole/commits/ca6510d929d16d8f5d59d472dc968ba597303f89">commits</a> 
nearly 100 years in the future</li>
</ul>
<p>None of this should be hugely surprising; people can write whatever they want
in their commit history, and sometimes they (or their tools) will write nonsense!
To them, it may not be nonsense.</p>
</li>
<li>
<p>The <a href="https://medium.com/google-cloud/github-on-bigquery-analyze-all-the-code-b3576fd2b150">GitHub press release</a> says that &quot;Forks and/or 
un-notable projects not included.&quot; I'm not so sure about that (c.f. the
multiple copies of Go mentioned above). Again, hardly surprising; it wouldn't
be easy for GitHub to reliably detect forks; it's perfectly possible to have
two completely separate projects that happen to share some commits, but neither
one obviusly be a fork of the other.</p>
</li>
</ul>
<p>In the query above, I've taken a few steps to try to filter out things that I'm
<em>guessing</em> are going to be more signal than noise:</p>
<ul>
<li>Ignore anything with a timestamp in Jan 1970. There certainly was software
development happening at the time, but from eyeballing the data, there're also
a lot of commits with dodgey timestamps.</li>
<li>Join on the somewhat cut-down <code>sample_repos</code> dataset, and filter for things with
some stars. This will exclude a lot of one-shot &quot;hobby&quot; projects that I suspect
would be a good addition to the dataset (many datapoints for &quot;projects that live
hardly any time at all&quot;), but I also suspect them of containing lots of junk,
and hope it might cut out some personal mirrors etc.</li>
</ul>
<p>So, what do we find?</p>
<h2>exploration</h2>
<p>Here are some plots of the distributions of project age.</p>
<p>First, a straightforward plot of the distribution of project lifetimes. On the
left is the whole dataset, and on the right are just those whose lifetimes
exceed 10 years:
<img src="lindy-tech/project_age_years_hist.svg" alt="Graph showing the distribution plot of project lifetimes in years" /></p>
<p>There are only 32 projects in the dataset with an age &gt; 20 years. That's such a
small number compared to the earlier samples that I'm going to exclude anything
with age &gt; 20 years from the following distribution plots. Chopping off this 
long tail may change the shape of the distribution, but I'll justify it by 
mentioning that even within this small sample, there are quite a few projects 
that are clearly noise rather than signal:</p>
<ul>
<li><a href="https://github.com/scwuaptx/CTF">scwuaptx/CTF</a> - writeups of CTFs, which look to
only really go back as far as 2015</li>
<li><a href="https://github.com/eregon/mozart-graal">eregon/mozart-graal</a> - a project
built on top of the <a href="https://en.wikipedia.org/wiki/GraalVM">GraalVM</a>, whose
first &quot;production ready&quot; release was in 2019.</li>
</ul>
<p>The cost is excluding (several forks of...) projects like Emacs.</p>
<p>Each of the following graphs is a <a href="https://seaborn.pydata.org/tutorial/distributions.html">seaborn distplot</a>
showing project age (in years) on the x-axis and the kernel density estimate
the y-axis. </p>
<p>First, the distribution of what's left after filtering:
<img src="lindy-tech/project-age-simple-distribution.svg" alt="Graph showing the distribution plot of project lifetimes in years, excluding those with age &gt; 20 years" /></p>
<p>Next, the same data on a log scale (filtered for only projects with age &lt; 20 years):
<img src="lindy-tech/project-age-log-distribution-filtered.svg" alt="Graph showing the distribution plot of project lifetimes in years with a logarithmic y-axis" /></p>
<p>Finally, the same data on a log-log scale:
<img src="lindy-tech/project-age-log-log-distribution-filtered.svg" alt="Graph showing the distribution plot of project lifetimes in years with a logarithmic y-axis and logarithmic x-axis" /></p>
<p>A couple of observations:</p>
<ul>
<li>Power-law distributions (of the type described by Taleb's expression of the 
Lindy Effect above) <a href="https://en.wikipedia.org/wiki/Power_law#Graphical_methods_for_identification">show a straight line on a log-log plot</a>
as a necessary-but-not-sufficient condition. We see something a bit like that,
after around the 4 year mark. </li>
<li>We see a clear straight downward slope on the log-graph, once a project reaches
its fourth year.</li>
</ul>
<h2>results</h2>
<p>Now, back to our hypothesis:</p>
<blockquote>
<p>The longer a project has been around, the longer its expected remaining life.</p>
</blockquote>
<p>Let's look at two graphs of expected (mean) lifespan (on the y-axis), predicated
on current lifespan in years (on the x-axis). The <em>nth-percentile</em> lines show the
distribution of our sample data. First, let's zoom out and get the fullest 
picture we can; we'll re-include the 32 projects with a lifespan &gt; 20 years:</p>
<p><img src="lindy-tech/remaining_life_expectancy_all.svg" alt="Graph showing a steep upward slope of projects' remaining life expectancy after they pass 6 years of age" /></p>
<p>Woah there. A couple of things jump out:</p>
<ul>
<li>This graph seems to imply that our hypothesis has some merit (in terms of 
mean life expectancy, at least), in a big way for older projects: a 
project's remaining life expectancy ramps up damatically after about 15 
years or so.</li>
<li>Our 30th- and 50th-percentile lines <em>stay</em> low, never exceeding the 2 year 
mark while we have &gt;100 projects in the sample.</li>
<li>Mean life expectancies seem to be dominated by a few very long-lived projects,
but remember, we've only got 32 data points after the 20 year mark, and as we
discussed above, it's not clear that these represent particularly useful data 
points. To emphasize how little data we have here, I've included the sample
counts on the right-hand axis (in grey).</li>
</ul>
<p>What can we do about this?</p>
<ul>
<li>If we chop the data down to exclude data points greater than, say, 15
years, then we will be imposing an artificial limit on the upper bound 
of life expectancy. This would rule out our hypothesis by construction.</li>
<li>We can keep all the data, but only look at the remaining life expectancies
for those with &quot;enough&quot; data points after them to make some resonable
judgement of what that expectancy might be.</li>
</ul>
<p>I've done... a mix:</p>
<ul>
<li>I've projected the remaining life expectancy only of projects up to 10 years
of age. There are still a decent number of projects older than that that we can
hope to use to estimate a life expectancy.</li>
<li>To estimate that remaining life expectancy, I've excluded projects where
the recorded life span is &gt; 30 years. The projects in that group are just 
too noisey to consider.</li>
</ul>
<p>So, I have imposed an artificial limit on project life (30 years), but 
hopefully that's high enough that it's not going to skew the results for 
projects we consider (10 years or younger). I'd love to hear from someone more
statistically literate if there's a better way to go about this - I'm sure there
must be.</p>
<p>So, finally, here's a graph showing expected remaining life expectancy of a
project, given its current age. </p>
<p><img src="lindy-tech/remaining_life_expectancy_sub_10.svg" alt="Graph showing remaining life expectancy of projects up to 10 years of age" /></p>
<p>Nothing really jumps out here; so I'll venture some more modest conclusions:</p>
<ul>
<li>By our measure of project lifetime, age doesn't seem to tell us anything
much about expected remaining life expectancy. That's more &quot;lindy&quot; than, say,
remaining human life expectancy (broadly, decreases as we age), but doesn't 
show the kind of growth I expected.</li>
<li>Even projects that have been going for some years are more likely than not to
meet our definition of &quot;done&quot; over the next two. That certainly doesn't match
my intuition; I expected that network effects and inertia would play a big part
in extending the longevity of projects that had been going for a long time. 
Perhaps that's an indictment of our definition of &quot;done&quot;.</li>
</ul>
<h2>further work</h2>
<p>Better analysis:</p>
<ul>
<li>I've used a very crude measure of project liveness: looking only at
commits. It's perfectly possible for a project to have an active and
engaged community, with no code changes for a few months. A smattering of
things I'd want to think about for a really confident idea of a project 
being &quot;done&quot; might include:
<ul>
<li>Are new issues being filed in the issue tracker? This implies that
<em>someone</em> is still using it.</li>
<li>Are issues being responded to?</li>
<li>Is there an active StackOverflow community?</li>
</ul>
</li>
<li>Cohorting of project types; perhaps libraries have very different
lifecycles to programming languages? How about frameworks vs. libraries?
Applications? Personal websites, like this one?</li>
</ul>
<p>Sources of bias in the data:</p>
<ul>
<li>How to account for still-live projects? This analysis excludes any projects
that are still active - and if the original hypothesis is true (longer-lived 
projects will stay active), then this sampling bias will skew results against
that conclusion.</li>
<li>There are plenty of long-lived projects that would meaningfully contribute 
to the long tail. By excluding the really &quot;old&quot; projects, I'm excluding 
exactly those that could provide the most interesting data points.</li>
<li>The original dataset as derived from the GitHub public data is not reflective
of all open source projects. Some notable exclusions:
<ul>
<li>Corporate / closed-open-source. These projects have diffirent
fundamentals affecting their lifetimes. Whilst many open source projects
rest on the labour of a few individuals, corporates replace individual team
members, and I venture that <em>most</em> professional engineers will have at some
point worked on systems where none of the original authors is still on the 
team.</li>
<li>There is an open-source world beyond GitHub, and the older the project, the
more likely that it had some established code hosting solution before
GitHub rose to prominence. Some of those projects will be included via
GitHub-hosted mirrors, but certainly not all. </li>
</ul>
</li>
</ul>

        </main>
    </article>

    
    <script data-goatcounter="https://jelford.goatcounter.com/count"
        async src="/assets/vendor/goatcounter.js"></script>
    </body>
</html>
